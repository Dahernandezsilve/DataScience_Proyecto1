{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Universidad del Valle de Guatemala\n",
    "## Facultad de Ingenier√≠a\n",
    "### Departamento de Computaci√≥n\n",
    "\n",
    "---\n",
    "\n",
    "# Proyecto 1: Establecimientos educativos de Guatemala\n",
    "## Avances del proyecto 1. Limpieza de datos - Dataset: Establecimientos educativos de Guatemala\n",
    "\n",
    "**Integrantes:**\n",
    "- Diego Alexander Hern√°ndez Silvestre, 21270\n",
    "- Linda In√©s Jim√©nez Vides, 21169\n",
    "- Mario Antonio Guerra Morales, 21008\n",
    "- David Jonathan Aragon Vasquez, 21053\n",
    "\n",
    "**Curso:** Data Science  \n",
    "**Secci√≥n:** 10  \n",
    "**Grupo** 4  \n",
    "\n",
    "---\n",
    "\n",
    "Guatemala, 25 de julio de 2024\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar las librer√≠as necesarias\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import csv\n",
    "from bs4 import BeautifulSoup\n",
    "from ucimlrepo import fetch_ucirepo \n",
    "from pydantic_settings import BaseSettings\n",
    "from imblearn.combine import SMOTEENN\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìú **Conversi√≥n de HTML y XLS a CSV**\n",
    "\n",
    "1. **üîç Buscar Tablas en HTML**: \n",
    "   - Convierte el contenido HTML con tablas a formato CSV. üóÇÔ∏è\n",
    "\n",
    "2. **üîÑ Procesar Archivos**: \n",
    "   - Lee archivos `.xls` y convierte datos a HTML para luego a CSV. üóÉÔ∏è\n",
    "\n",
    "3. **üîÑ Convertir a CSV**: \n",
    "   - Convierte archivos `.xls` en un directorio y sus subdirectorios a CSV. üìÅ\n",
    "\n",
    "4. **üö´ Manejo de Errores**: \n",
    "   - Maneja errores de lectura y conversi√≥n para archivos corruptos. ‚ö†Ô∏è\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error al crear el CSV para Data/ALTA_VERAPAZ\\establecimiento.csv: 6393 columns passed, passed data had 17 columns\n",
      "Convertido HTML a CSV en Data/ALTA_VERAPAZ\\establecimiento.csv\n",
      "Error al crear el CSV para Data/BAJA_VERAPAZ\\establecimiento.csv: 1973 columns passed, passed data had 17 columns\n",
      "Convertido HTML a CSV en Data/BAJA_VERAPAZ\\establecimiento.csv\n",
      "Error al crear el CSV para Data/CHIMALTENANGO\\establecimiento.csv: 6138 columns passed, passed data had 17 columns\n",
      "Convertido HTML a CSV en Data/CHIMALTENANGO\\establecimiento.csv\n",
      "Error al crear el CSV para Data/CHIQUIMULA\\establecimiento.csv: 2925 columns passed, passed data had 17 columns\n",
      "Convertido HTML a CSV en Data/CHIQUIMULA\\establecimiento.csv\n",
      "Error al crear el CSV para Data/CIUDAD_CAPITAL\\establecimiento.csv: 26623 columns passed, passed data had 17 columns\n",
      "Convertido HTML a CSV en Data/CIUDAD_CAPITAL\\establecimiento.csv\n",
      "Error al crear el CSV para Data/EL_PROGRESO\\establecimiento.csv: 2160 columns passed, passed data had 17 columns\n",
      "Convertido HTML a CSV en Data/EL_PROGRESO\\establecimiento.csv\n",
      "Error al crear el CSV para Data/ESCUINTLA\\establecimiento.csv: 10711 columns passed, passed data had 17 columns\n",
      "Convertido HTML a CSV en Data/ESCUINTLA\\establecimiento.csv\n",
      "Error al crear el CSV para Data/GUATEMALA\\establecimiento.csv: 25144 columns passed, passed data had 17 columns\n",
      "Convertido HTML a CSV en Data/GUATEMALA\\establecimiento.csv\n",
      "Error al crear el CSV para Data/HUEHUETENANGO\\establecimiento.csv: 8807 columns passed, passed data had 17 columns\n",
      "Convertido HTML a CSV en Data/HUEHUETENANGO\\establecimiento.csv\n",
      "Error al crear el CSV para Data/IZABAL\\establecimiento.csv: 6291 columns passed, passed data had 17 columns\n",
      "Convertido HTML a CSV en Data/IZABAL\\establecimiento.csv\n",
      "Error al crear el CSV para Data/JALAPA\\establecimiento.csv: 2602 columns passed, passed data had 17 columns\n",
      "Convertido HTML a CSV en Data/JALAPA\\establecimiento.csv\n",
      "Error al crear el CSV para Data/JUTIAPA\\establecimiento.csv: 5305 columns passed, passed data had 17 columns\n",
      "Convertido HTML a CSV en Data/JUTIAPA\\establecimiento.csv\n",
      "Error al crear el CSV para Data/PETEN\\establecimiento.csv: 6257 columns passed, passed data had 17 columns\n",
      "Convertido HTML a CSV en Data/PETEN\\establecimiento.csv\n",
      "Error al crear el CSV para Data/QUETZALTENANGO\\establecimiento.csv: 8382 columns passed, passed data had 17 columns\n",
      "Convertido HTML a CSV en Data/QUETZALTENANGO\\establecimiento.csv\n",
      "Error al crear el CSV para Data/QUICHE\\establecimiento.csv: 4183 columns passed, passed data had 17 columns\n",
      "Convertido HTML a CSV en Data/QUICHE\\establecimiento.csv\n",
      "Error al crear el CSV para Data/RETALHULEU\\establecimiento.csv: 5407 columns passed, passed data had 17 columns\n",
      "Convertido HTML a CSV en Data/RETALHULEU\\establecimiento.csv\n",
      "Error al crear el CSV para Data/SACATEPEQUEZ\\establecimiento.csv: 5458 columns passed, passed data had 17 columns\n",
      "Convertido HTML a CSV en Data/SACATEPEQUEZ\\establecimiento.csv\n",
      "Error al crear el CSV para Data/SANTA_ROSA\\establecimiento.csv: 2704 columns passed, passed data had 17 columns\n",
      "Convertido HTML a CSV en Data/SANTA_ROSA\\establecimiento.csv\n",
      "Error al crear el CSV para Data/SAN_MARCOS\\establecimiento.csv: 9793 columns passed, passed data had 17 columns\n",
      "Convertido HTML a CSV en Data/SAN_MARCOS\\establecimiento.csv\n",
      "Error al crear el CSV para Data/SOLOLA\\establecimiento.csv: 2381 columns passed, passed data had 17 columns\n",
      "Convertido HTML a CSV en Data/SOLOLA\\establecimiento.csv\n",
      "Error al crear el CSV para Data/SUCHITEPEQUEZ\\establecimiento.csv: 6580 columns passed, passed data had 17 columns\n",
      "Convertido HTML a CSV en Data/SUCHITEPEQUEZ\\establecimiento.csv\n",
      "Error al crear el CSV para Data/TOTONICAPAN\\establecimiento.csv: 1565 columns passed, passed data had 17 columns\n",
      "Convertido HTML a CSV en Data/TOTONICAPAN\\establecimiento.csv\n",
      "Error al crear el CSV para Data/ZACAPA\\establecimiento.csv: 1633 columns passed, passed data had 17 columns\n",
      "Convertido HTML a CSV en Data/ZACAPA\\establecimiento.csv\n"
     ]
    }
   ],
   "source": [
    "def convert_html_table_to_csv(html_content, csv_path):\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "    tables = soup.find_all('table')\n",
    "    \n",
    "    if not tables:\n",
    "        raise ValueError(\"No se encontr√≥ ninguna tabla en el contenido HTML.\")\n",
    "    \n",
    "    for table in tables:\n",
    "        headers = [th.get_text(strip=True) for th in table.find_all('th')]\n",
    "        if not headers:\n",
    "            headers = [td.get_text(strip=True) for td in table.find_all('tr')[0].find_all('td')]\n",
    "\n",
    "        rows = []\n",
    "        for row in table.find_all('tr')[1:]:\n",
    "            cells = [td.get_text(strip=True) for td in row.find_all('td')]\n",
    "            if cells:\n",
    "                rows.append(cells)\n",
    "\n",
    "        if headers and rows:\n",
    "            try:\n",
    "                df = pd.DataFrame(rows, columns=headers)\n",
    "                df.to_csv(csv_path, index=False, quoting=csv.QUOTE_NONNUMERIC)\n",
    "                print(f\"Convertido HTML a CSV en {csv_path}\")\n",
    "                break  # Salir del bucle si la tabla se convirti√≥ correctamente\n",
    "            except Exception as e:\n",
    "                print(f\"Error al crear el CSV para {csv_path}: {e}\")\n",
    "                continue\n",
    "\n",
    "def process_file(file_path, csv_path):\n",
    "    try:\n",
    "        # Intentar leer el archivo como texto bruto y tratarlo como HTML\n",
    "        with open(file_path, 'r', encoding='latin1') as file:\n",
    "            html_content = file.read()\n",
    "            convert_html_table_to_csv(html_content, csv_path)\n",
    "    except (UnicodeDecodeError, IOError):\n",
    "        try:\n",
    "            # Leer el archivo .xls usando pandas si es un archivo Excel v√°lido\n",
    "            # Nota: Esto puede fallar si el archivo est√° corrupto\n",
    "            try:\n",
    "                df = pd.read_excel(file_path, engine='openpyxl')\n",
    "                html_content = df.to_html(index=False)\n",
    "                convert_html_table_to_csv(html_content, csv_path)\n",
    "            except Exception as e:\n",
    "                print(f\"No se pudo leer el archivo Excel {file_path}: {e}\")\n",
    "        except Exception as e:\n",
    "            print(f\"No se pudo procesar {file_path}: {e}\")\n",
    "\n",
    "def convert_xls_to_csv(root_directory):\n",
    "    for subdir, _, files in os.walk(root_directory):\n",
    "        for file in files:\n",
    "            if file.endswith(\".xls\"):\n",
    "                file_path = os.path.join(subdir, file)\n",
    "                csv_filename = file.replace(\".xls\", \".csv\")\n",
    "                csv_path = os.path.join(subdir, csv_filename)\n",
    "                process_file(file_path, csv_path)\n",
    "\n",
    "# Especifica el directorio ra√≠z que contiene los archivos .xls y subdirectorios\n",
    "root_directory = \"Data/\"\n",
    "\n",
    "convert_xls_to_csv(root_directory)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üóëÔ∏è **Eliminaci√≥n de Filas Vac√≠as en CSV**\n",
    "\n",
    "1. **üì• Leer CSV**: \n",
    "   - Lee archivos CSV desde el directorio especificado. üìÑ\n",
    "\n",
    "2. **üßπ Limpiar Datos**: \n",
    "   - Elimina filas donde todas las celdas est√°n vac√≠as. üöÆ\n",
    "\n",
    "3. **üìà Reportar Cambios**: \n",
    "   - Guarda el archivo limpio y muestra cu√°ntas filas fueron eliminadas. üìä\n",
    "\n",
    "4. **üîÑ Procesar Todos los CSV**: \n",
    "   - Procesa todos los archivos CSV en el directorio, exceptuando los ya procesados. üìÅ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo procesado guardado en Data/ALTA_VERAPAZ\\establecimiento_processed.csv. Filas eliminadas: 1\n",
      "Archivo procesado guardado en Data/BAJA_VERAPAZ\\establecimiento_processed.csv. Filas eliminadas: 1\n",
      "Archivo procesado guardado en Data/CHIMALTENANGO\\establecimiento_processed.csv. Filas eliminadas: 1\n",
      "Archivo procesado guardado en Data/CHIQUIMULA\\establecimiento_processed.csv. Filas eliminadas: 1\n",
      "Archivo procesado guardado en Data/CIUDAD_CAPITAL\\establecimiento_processed.csv. Filas eliminadas: 1\n",
      "Archivo procesado guardado en Data/EL_PROGRESO\\establecimiento_processed.csv. Filas eliminadas: 1\n",
      "Archivo procesado guardado en Data/ESCUINTLA\\establecimiento_processed.csv. Filas eliminadas: 1\n",
      "Archivo procesado guardado en Data/GUATEMALA\\establecimiento_processed.csv. Filas eliminadas: 1\n",
      "Archivo procesado guardado en Data/HUEHUETENANGO\\establecimiento_processed.csv. Filas eliminadas: 1\n",
      "Archivo procesado guardado en Data/IZABAL\\establecimiento_processed.csv. Filas eliminadas: 1\n",
      "Archivo procesado guardado en Data/JALAPA\\establecimiento_processed.csv. Filas eliminadas: 1\n",
      "Archivo procesado guardado en Data/JUTIAPA\\establecimiento_processed.csv. Filas eliminadas: 1\n",
      "Archivo procesado guardado en Data/PETEN\\establecimiento_processed.csv. Filas eliminadas: 1\n",
      "Archivo procesado guardado en Data/QUETZALTENANGO\\establecimiento_processed.csv. Filas eliminadas: 1\n",
      "Archivo procesado guardado en Data/QUICHE\\establecimiento_processed.csv. Filas eliminadas: 1\n",
      "Archivo procesado guardado en Data/RETALHULEU\\establecimiento_processed.csv. Filas eliminadas: 1\n",
      "Archivo procesado guardado en Data/SACATEPEQUEZ\\establecimiento_processed.csv. Filas eliminadas: 1\n",
      "Archivo procesado guardado en Data/SANTA_ROSA\\establecimiento_processed.csv. Filas eliminadas: 1\n",
      "Archivo procesado guardado en Data/SAN_MARCOS\\establecimiento_processed.csv. Filas eliminadas: 1\n",
      "Archivo procesado guardado en Data/SOLOLA\\establecimiento_processed.csv. Filas eliminadas: 1\n",
      "Archivo procesado guardado en Data/SUCHITEPEQUEZ\\establecimiento_processed.csv. Filas eliminadas: 1\n",
      "Archivo procesado guardado en Data/TOTONICAPAN\\establecimiento_processed.csv. Filas eliminadas: 1\n",
      "Archivo procesado guardado en Data/ZACAPA\\establecimiento_processed.csv. Filas eliminadas: 1\n"
     ]
    }
   ],
   "source": [
    "def remove_empty_rows_from_csv(csv_path, processed_csv_path):\n",
    "    try:\n",
    "        # Leer el archivo CSV\n",
    "        df = pd.read_csv(csv_path)\n",
    "\n",
    "        # Contar el n√∫mero de filas originales\n",
    "        original_row_count = len(df)\n",
    "\n",
    "        # Eliminar filas donde todas las celdas est√°n vac√≠as\n",
    "        df_cleaned = df.dropna(how='all')\n",
    "\n",
    "        # Contar el n√∫mero de filas despu√©s de eliminar las vac√≠as\n",
    "        cleaned_row_count = len(df_cleaned)\n",
    "\n",
    "        # Contar cu√°ntas filas fueron eliminadas\n",
    "        rows_removed = original_row_count - cleaned_row_count\n",
    "\n",
    "        # Guardar el DataFrame limpio en un nuevo archivo CSV\n",
    "        df_cleaned.to_csv(processed_csv_path, index=False, quoting=csv.QUOTE_NONNUMERIC)\n",
    "\n",
    "        # Informar cu√°ntas filas fueron eliminadas\n",
    "        print(f\"Archivo procesado guardado en {processed_csv_path}. Filas eliminadas: {rows_removed}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"No se pudo procesar el archivo {csv_path}: {e}\")\n",
    "\n",
    "def process_all_csv_files(root_directory):\n",
    "    for subdir, _, files in os.walk(root_directory):\n",
    "        for file in files:\n",
    "            if file.endswith(\".csv\") and not file.endswith(\"processed.csv\"):\n",
    "                csv_path = os.path.join(subdir, file)\n",
    "                processed_csv_path = os.path.join(subdir, file.replace(\".csv\", \"_processed.csv\"))\n",
    "                remove_empty_rows_from_csv(csv_path, processed_csv_path)\n",
    "\n",
    "# Especifica el directorio ra√≠z que contiene los archivos CSV\n",
    "root_directory = \"Data/\"\n",
    "\n",
    "process_all_csv_files(root_directory)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
